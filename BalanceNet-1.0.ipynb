{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BalanceNet prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:04.496667Z",
     "start_time": "2018-06-06T18:53:34.604358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.6B.200d.txt\n",
      "[i] Importing Modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Using Keras version 2.1.5\n",
      "[+] Finished Importing Modules\n",
      "[i] Reading from csv file...Done!\n",
      "[i] Found 34359 unique tokens.\n",
      "[+] Shape of data tensor: (47288, 30)\n",
      "[+] Shape of label tensor: (47288, 5)\n",
      "[i] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7714. 13001. 12743.  3478.   895.]\n",
      "[+] Validation:\n",
      " [1929. 3296. 3195.  823.  214.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.6B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...[i] Completed!\n",
      "[i] Finished running setup.\n"
     ]
    }
   ],
   "source": [
    "%run Setup.ipynb\n",
    "%run ExtraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:04.668782Z",
     "start_time": "2018-06-06T18:54:04.499126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# second embedding matrix for non-static channel\n",
    "embedding_matrix_ns = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_ns[i] = embedding_vector\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:05.016071Z",
     "start_time": "2018-06-06T18:54:04.672217Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "# static channel\n",
    "embedding_layer_frozen = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "embedded_sequences_frozen = embedding_layer_frozen(sequence_input)\n",
    "\n",
    "# non-static channel\n",
    "embedding_layer_train = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix_ns],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "embedded_sequences_train = embedding_layer_train(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Half: LSTM > CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:06.120868Z",
     "start_time": "2018-06-06T18:54:05.019182Z"
    }
   },
   "outputs": [],
   "source": [
    "l_lstm1f = Bidirectional(LSTM(6,return_sequences=True,dropout=0.3, recurrent_dropout=0.0))(embedded_sequences_frozen)\n",
    "l_lstm1t = Bidirectional(LSTM(6,return_sequences=True,dropout=0.3, recurrent_dropout=0.0))(embedded_sequences_train)\n",
    "l_lstm1 = Concatenate(axis=1)([l_lstm1f, l_lstm1t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:06.556182Z",
     "start_time": "2018-06-06T18:54:06.129196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "l_conv_2 = Conv1D(filters=24,kernel_size=2,activation='relu')(l_lstm1)\n",
    "l_conv_2 = Dropout(0.3)(l_conv_2)\n",
    "l_conv_3 = Conv1D(filters=24,kernel_size=3,activation='relu')(l_lstm1)\n",
    "l_conv_3 = Dropout(0.3)(l_conv_3)\n",
    "\n",
    "l_conv_5 = Conv1D(filters=24,kernel_size=5,activation='relu',)(l_lstm1)\n",
    "l_conv_5 = Dropout(0.3)(l_conv_5)\n",
    "l_conv_6 = Conv1D(filters=24,kernel_size=6,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(l_lstm1)\n",
    "l_conv_6 = Dropout(0.3)(l_conv_6)\n",
    "\n",
    "l_conv_8 = Conv1D(filters=24,kernel_size=8,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(l_lstm1)\n",
    "l_conv_8 = Dropout(0.3)(l_conv_8)\n",
    "\n",
    "conv_1 = [l_conv_6,l_conv_5, l_conv_8,l_conv_2,l_conv_3]\n",
    "\n",
    "l_lstm_c = Concatenate(axis=1)(conv_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Half: CNN > LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:07.523503Z",
     "start_time": "2018-06-06T18:54:06.558877Z"
    }
   },
   "outputs": [],
   "source": [
    "l_conv_4f = Conv1D(filters=12,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(embedded_sequences_frozen)\n",
    "l_conv_4f = Dropout(0.3)(l_conv_4f)\n",
    "l_conv_4t = Conv1D(filters=12,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(embedded_sequences_train)\n",
    "l_conv_4t = Dropout(0.3)(l_conv_4t)\n",
    "\n",
    "l_conv_3f = Conv1D(filters=12,kernel_size=3,activation='relu',)(embedded_sequences_frozen)\n",
    "l_conv_3f = Dropout(0.3)(l_conv_3f)\n",
    "l_conv_3t = Conv1D(filters=12,kernel_size=3,activation='relu',)(embedded_sequences_train)\n",
    "l_conv_3t = Dropout(0.3)(l_conv_3t)\n",
    "\n",
    "l_conv_2f = Conv1D(filters=12,kernel_size=2,activation='relu')(embedded_sequences_frozen)\n",
    "l_conv_2f = Dropout(0.3)(l_conv_2f)\n",
    "l_conv_2t = Conv1D(filters=12,kernel_size=2,activation='relu')(embedded_sequences_train)\n",
    "l_conv_2t = Dropout(0.3)(l_conv_2t)\n",
    "\n",
    "conv_2 = [l_conv_4f, l_conv_4t,l_conv_3f, l_conv_3t, l_conv_2f, l_conv_2t]\n",
    "\n",
    "l_merge_2 = Concatenate(axis=1)(conv_2)\n",
    "l_c_lstm = Bidirectional(LSTM(12,return_sequences=True,dropout=0.3, recurrent_dropout=0.0))(l_merge_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both halfs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:07.611496Z",
     "start_time": "2018-06-06T18:54:07.527424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cut the whole left branch\n",
    "l_merge = Concatenate(axis=1)([l_lstm_c, l_c_lstm])\n",
    "l_pool = MaxPooling1D(4)(l_c_lstm)\n",
    "l_drop = Dropout(0.5)(l_pool)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(26, activation='relu')(l_flat)\n",
    "preds = Dense(5, activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:07.760764Z",
     "start_time": "2018-06-06T18:54:07.613807Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "adadelta = optimizers.Adadelta(lr=0.9, rho=0.95, epsilon=None, decay=0.002)\n",
    "lr_metric = get_lr_metric(adadelta)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adadelta,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:07.900464Z",
     "start_time": "2018-06-06T18:54:07.763142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:13.451482Z",
     "start_time": "2018-06-06T18:54:07.903481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "tensorboard = callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_grads=True , write_graph=True)\n",
    "model_checkpoints = callbacks.ModelCheckpoint(\"checkpoint-{val_loss:.3f}.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=0)\n",
    "lr_schedule = callbacks.LearningRateScheduler(initial_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:14.292094Z",
     "start_time": "2018-06-06T18:54:13.454552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 200)      6872000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 200)      6872000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 27, 12)       9612        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 27, 12)       9612        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 28, 12)       7212        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 28, 12)       7212        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 29, 12)       4812        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 29, 12)       4812        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 27, 12)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 27, 12)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 12)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 12)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 29, 12)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 29, 12)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 168, 12)      0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "                                                                 dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 168, 24)      2400        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 42, 24)       0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 42, 24)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1008)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 26)           26234       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            135         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,816,041\n",
      "Trainable params: 6,944,041\n",
      "Non-trainable params: 6,872,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('BalanceNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T18:54:15.839947Z",
     "start_time": "2018-06-06T18:54:14.295516Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"BalanceNet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:39:40.718273Z",
     "start_time": "2018-06-06T19:44:19.296264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress:\n",
      "Train on 37831 samples, validate on 9457 samples\n",
      "Epoch 1/25\n",
      "37831/37831 [==============================] - 130s 3ms/step - loss: 0.9684 - acc: 0.6009 - val_loss: 0.9620 - val_acc: 0.5970\n",
      "Epoch 2/25\n",
      "37831/37831 [==============================] - 130s 3ms/step - loss: 0.9613 - acc: 0.6029 - val_loss: 0.9549 - val_acc: 0.6035\n",
      "Epoch 3/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9567 - acc: 0.6050 - val_loss: 0.9485 - val_acc: 0.6054\n",
      "Epoch 4/25\n",
      "37831/37831 [==============================] - 132s 3ms/step - loss: 0.9462 - acc: 0.6097 - val_loss: 0.9461 - val_acc: 0.6079\n",
      "Epoch 5/25\n",
      "37831/37831 [==============================] - 134s 4ms/step - loss: 0.9410 - acc: 0.6118 - val_loss: 0.9429 - val_acc: 0.6084\n",
      "Epoch 6/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9375 - acc: 0.6137 - val_loss: 0.9432 - val_acc: 0.6090\n",
      "Epoch 7/25\n",
      "37831/37831 [==============================] - 132s 3ms/step - loss: 0.9315 - acc: 0.6174 - val_loss: 0.9460 - val_acc: 0.6076\n",
      "Epoch 8/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9280 - acc: 0.6170 - val_loss: 0.9493 - val_acc: 0.6072\n",
      "Epoch 9/25\n",
      "37831/37831 [==============================] - 131s 3ms/step - loss: 0.9247 - acc: 0.6203 - val_loss: 0.9409 - val_acc: 0.6090\n",
      "Epoch 10/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9224 - acc: 0.6224 - val_loss: 0.9401 - val_acc: 0.6108\n",
      "Epoch 11/25\n",
      "37831/37831 [==============================] - 135s 4ms/step - loss: 0.9191 - acc: 0.6192 - val_loss: 0.9376 - val_acc: 0.6116\n",
      "Epoch 12/25\n",
      "37831/37831 [==============================] - 139s 4ms/step - loss: 0.9180 - acc: 0.6248 - val_loss: 0.9377 - val_acc: 0.6085\n",
      "Epoch 13/25\n",
      "37831/37831 [==============================] - 139s 4ms/step - loss: 0.9153 - acc: 0.6230 - val_loss: 0.9362 - val_acc: 0.6117\n",
      "Epoch 14/25\n",
      "37831/37831 [==============================] - 134s 4ms/step - loss: 0.9111 - acc: 0.6269 - val_loss: 0.9395 - val_acc: 0.6129\n",
      "Epoch 15/25\n",
      "37831/37831 [==============================] - 132s 3ms/step - loss: 0.9122 - acc: 0.6247 - val_loss: 0.9355 - val_acc: 0.6111\n",
      "Epoch 16/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9085 - acc: 0.6282 - val_loss: 0.9354 - val_acc: 0.6119\n",
      "Epoch 17/25\n",
      "37831/37831 [==============================] - 130s 3ms/step - loss: 0.9061 - acc: 0.6274 - val_loss: 0.9333 - val_acc: 0.6101\n",
      "Epoch 18/25\n",
      "37831/37831 [==============================] - 134s 4ms/step - loss: 0.9032 - acc: 0.6289 - val_loss: 0.9364 - val_acc: 0.6116\n",
      "Epoch 19/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9006 - acc: 0.6292 - val_loss: 0.9355 - val_acc: 0.6122\n",
      "Epoch 20/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.9025 - acc: 0.6307 - val_loss: 0.9351 - val_acc: 0.6133\n",
      "Epoch 21/25\n",
      "37831/37831 [==============================] - 133s 4ms/step - loss: 0.8988 - acc: 0.6291 - val_loss: 0.9351 - val_acc: 0.6132\n",
      "Epoch 22/25\n",
      "37831/37831 [==============================] - 129s 3ms/step - loss: 0.8931 - acc: 0.6341 - val_loss: 0.9347 - val_acc: 0.6110\n",
      "Epoch 23/25\n",
      "37831/37831 [==============================] - 131s 3ms/step - loss: 0.8930 - acc: 0.6342 - val_loss: 0.9349 - val_acc: 0.6107\n",
      "Epoch 24/25\n",
      "37831/37831 [==============================] - 131s 3ms/step - loss: 0.8920 - acc: 0.6335 - val_loss: 0.9350 - val_acc: 0.6119\n",
      "Epoch 25/25\n",
      "37831/37831 [==============================] - 130s 3ms/step - loss: 0.8952 - acc: 0.6337 - val_loss: 0.9325 - val_acc: 0.6114\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Progress:\")\n",
    "model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=25, batch_size=128,\n",
    "          callbacks=[tensorboard, model_checkpoints])\n",
    "\n",
    "pd.DataFrame(model_log.history).to_csv(\"history-balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:41:48.477613Z",
     "start_time": "2018-06-06T20:41:48.279303Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('BalanceNet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics\n",
    "\n",
    "Load the lyrics dataset now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:50:46.959905Z",
     "start_time": "2018-06-06T20:50:21.773716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.6B.200d.txt\n",
      "[i] Importing Modules...\n",
      "[+] Using Keras version 2.1.5\n",
      "[+] Finished Importing Modules\n",
      "[i] Reading from csv file...Done!\n",
      "[i] Found 34359 unique tokens.\n",
      "[+] Shape of data tensor: (1948, 30)\n",
      "[+] Shape of label tensor: (1948, 4)\n",
      "[i] Number of entries in each category:\n",
      "[+] Training:\n",
      " [400. 381. 388. 390.]\n",
      "[+] Validation:\n",
      " [ 92. 104.  98.  95.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.6B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...[i] Completed!\n",
      "[i] Finished running setup.\n"
     ]
    }
   ],
   "source": [
    "%run Setup_lyrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:53:20.438995Z",
     "start_time": "2018-06-06T20:53:18.212361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cut the network after the convolutional layer\n",
    "layer_name = 'flatten_1'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "# Generate intermediate predictions\n",
    "intermediate_prediction_train = intermediate_layer_model.predict(x_train)\n",
    "intermediate_prediction_test = intermediate_layer_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:56:10.557416Z",
     "start_time": "2018-06-06T20:56:10.552088Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_label = np.argmax(y_train, axis=1)\n",
    "y_test_label = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:57:31.724834Z",
     "start_time": "2018-06-06T20:57:27.195200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.33161953727506427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Naive Bayes Classifer on intermediate predictions\n",
    "clf = LogisticRegression(penalty='l2', dual=False, C=25,\n",
    "                                    solver='newton-cg', multi_class='multinomial', random_state=0)\n",
    "clf.fit(intermediate_prediction_train, y_train_label)\n",
    "print('Logistic regression accuracy:', clf.score(intermediate_prediction_test, y_test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T20:59:32.775090Z",
     "start_time": "2018-06-06T20:59:32.698111Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "    \n",
    "from sklearn.utils import class_weight\n",
    "    \n",
    "def build_ann(optimizer='adam', input_size=1008):\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    # Add input layer\n",
    "    classifier = Sequential()\n",
    "    # Add input layer\n",
    "    classifier.add(Dense(units = 200, kernel_initializer = 'random_normal', activation = 'relu', input_dim = input_size))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    \n",
    "    # Add hidden layers\n",
    "    classifier.add(Dense(units = 100, kernel_initializer = 'random_normal', activation = 'relu'))\n",
    "    classifier.add(Dropout(0.1))\n",
    "                \n",
    "\n",
    "    classifier.add(Dense(units = 30, kernel_initializer = 'random_normal', activation = 'relu'))\n",
    "    classifier.add(Dropout(0.1))\n",
    "    \n",
    "        \n",
    "    # Add output layer\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'random_normal', activation = 'softmax'))\n",
    "    \n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T21:01:51.122958Z",
     "start_time": "2018-06-06T21:01:39.415932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8fb44eab00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "keras_classifier = KerasClassifier(build_fn=build_ann)\n",
    "keras_classifier.fit(intermediate_prediction_train, y_train, batch_size = 128, epochs = 100, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T21:01:51.557066Z",
     "start_time": "2018-06-06T21:01:51.125796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 0s 1ms/step\n",
      "Neural Network accuracy: 0.3264781491002571\n"
     ]
    }
   ],
   "source": [
    "print('Neural Network accuracy:', keras_classifier.score(intermediate_prediction_test, y_test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.196942Z",
     "start_time": "2018-06-06T16:59:28.626Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import itertools, pickle\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "#classes = [\"neutral\", \"happy\", \"sad\", \"hate\",\"anger\"]\n",
    "classes = ['angry', 'happy', 'relaxed', 'sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.198862Z",
     "start_time": "2018-06-06T16:59:29.251Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.200547Z",
     "start_time": "2018-06-06T16:59:31.249Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_test = load_model('checkpoint-0.866.h5')\n",
    "model_test = load_model('best_weights.h5')\n",
    "Y_test = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model_test.predict(x_val)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.202155Z",
     "start_time": "2018-06-06T16:59:34.019Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred_class, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.203695Z",
     "start_time": "2018-06-06T16:59:35.291Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, labels,\n",
    "                          normalize=True,\n",
    "                          title='Confusion Matrix (Validation Set)',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_confusion_matrix(cnf_matrix, labels=classes)\n",
    "\n",
    "# precision = true_pos / (true_pos + false_pos)\n",
    "# recall = true_pos / (true_pos + false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.205460Z",
     "start_time": "2018-06-06T16:59:36.901Z"
    }
   },
   "outputs": [],
   "source": [
    "text = [\"I salute you for the bravery and sacrifice! A true hero indeed.\",\n",
    "        \"I am sorry but I trust HRW I damned sight more than the PAP and it's cronies! Off course the PAP will say that they (HRW) made things up...despite of the fact that SG is a dictator state!?\",\n",
    "        \"PAP are taking the piss again!\",\n",
    "        \"Thought he sold his kidney to buy it; Instead, he bought a kidney then bought the car Filthy rich This is why we need communism\",\n",
    "        \"Somebody needs to water Tharman's head, hair needs to be grown there\",\n",
    "        \"what a nuisance fk. a proper clean and flat footpath,,now obstructed by sharedbikes..! which idiotic MP allowed this to happen?\",\n",
    "        \"What baby bonus scheme ??? To grow up a kid in Singapore you think is easy now bo ??? Both parent need to work to grow up a kid until 21 , you think tats easy bo ??? Think la\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.209006Z",
     "start_time": "2018-06-06T16:59:37.132Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(text)\n",
    "data_int_t = pad_sequences(sequences_test, padding='pre', maxlen=(MAX_SEQUENCE_LENGTH-5))\n",
    "data_test = pad_sequences(data_int_t, padding='post', maxlen=(MAX_SEQUENCE_LENGTH))\n",
    "y_prob = model.predict(data_test)\n",
    "for n, prediction in enumerate(y_prob):\n",
    "    pred = y_prob.argmax(axis=-1)[n]\n",
    "    print(text[n],\"\\nPrediction:\",classes[pred],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:59:46.211242Z",
     "start_time": "2018-06-06T16:59:38.747Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(sequences_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
